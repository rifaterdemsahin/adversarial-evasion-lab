# Adversarial Evasion Lab ğŸ¯

Welcome to the **Adversarial Evasion Lab**! This course will guide you through the fascinating world of adversarial machine learning, where we explore how attackers can fool AI systems and how to defend against such attacks.

## ğŸ“ Course Overview

This hands-on course teaches you about adversarial attacks and defenses in machine learning systems. You'll learn practical techniques through interactive Jupyter notebooks and real-world examples.

## ğŸ“š Course Structure

### Module 1: Evasion Attacks
- **M1_V1_FGSM**: Fast Gradient Sign Method - Learn about one of the most fundamental adversarial attack techniques

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8 or higher
- Basic understanding of machine learning concepts
- Familiarity with PyTorch

### Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/rifaterdemsahin/adversarial-evasion-lab.git
   cd adversarial-evasion-lab
   ```

2. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Launch Jupyter Notebook:
   ```bash
   jupyter notebook
   ```

4. Navigate to the module folders and open the notebooks to start learning!

## ğŸ“– What You'll Learn

- **Evasion Attacks**: Techniques to fool machine learning models
- **FGSM (Fast Gradient Sign Method)**: Understanding gradient-based attacks
- **Practical Implementation**: Hands-on coding with real examples
- **Defense Strategies**: How to protect models from adversarial attacks

## ğŸ› ï¸ Environment Setup

All dependencies are listed in `requirements.txt`. The main libraries used include:
- PyTorch for deep learning
- NumPy for numerical operations
- Matplotlib for visualization
- Adversarial Robustness Toolbox for attack implementations

## ğŸ“ License

This project is open source and available for educational purposes.

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the issues page.

Happy Learning! ğŸ‰